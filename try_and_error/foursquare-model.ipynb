{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.neighbors import BallTree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport Levenshtein\nimport difflib\nimport lightgbm as lgb\nimport collections\nfrom haversine import haversine\n","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:36:15.065962Z","iopub.execute_input":"2022-05-30T21:36:15.066462Z","iopub.status.idle":"2022-05-30T21:36:17.386206Z","shell.execute_reply.started":"2022-05-30T21:36:15.066354Z","shell.execute_reply":"2022-05-30T21:36:17.385115Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# read data\ntrain = pd.read_csv('../input/foursquare-location-matching/train.csv')\ntest = pd.read_csv('../input/foursquare-location-matching/test.csv')\nsample_submission = pd.read_csv('../input/foursquare-location-matching/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:36:17.387748Z","iopub.execute_input":"2022-05-30T21:36:17.388095Z","iopub.status.idle":"2022-05-30T21:36:26.143464Z","shell.execute_reply.started":"2022-05-30T21:36:17.388064Z","shell.execute_reply":"2022-05-30T21:36:26.142396Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Generate training data from train.csv","metadata":{}},{"cell_type":"code","source":"# 找出 train.csv 裡面每個 id 所匹配的 POI id\ntrue_matches = {} # dictionary, key=id, value=[matched ids]\n\nfor i, row in train.groupby('point_of_interest'): # 按照 POI 將資料分成群組\n    ids_ = set(row.id.values) # 無序集合且不包含重複資料\n    \n    for id_ in ids_:\n        true_matches[id_] = ids_\n        \n# true_matches","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:36:26.144657Z","iopub.execute_input":"2022-05-30T21:36:26.144980Z","iopub.status.idle":"2022-05-30T21:37:38.569459Z","shell.execute_reply.started":"2022-05-30T21:36:26.144951Z","shell.execute_reply":"2022-05-30T21:37:38.568436Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# for each id, find its nearest neighbors\n\ndef find_neighbors(df,neighbors):\n    knn = {} # dictionary, key=id, value=[neighbors ids]\n    knn_dist = []\n    rads = np.deg2rad(df[['latitude', 'longitude']].values)\n    tree = BallTree(rads, metric='haversine')\n    \n    for i in tqdm(range(len(df))):\n        dist, ind = tree.query(rads[i].reshape(1, -1), k = neighbors)\n        neighbors_list = []\n        for index in ind[0]:\n            neighbors_list.append(df['id'].loc[index])\n        \n        for d in dist[0]:\n            knn_dist.append(d)\n            \n        knn[df['id'].loc[i]] = neighbors_list\n        \n    return knn, knn_dist","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:37:38.571949Z","iopub.execute_input":"2022-05-30T21:37:38.572535Z","iopub.status.idle":"2022-05-30T21:37:38.585748Z","shell.execute_reply.started":"2022-05-30T21:37:38.572487Z","shell.execute_reply":"2022-05-30T21:37:38.584659Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"%load_ext Cython","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:37:38.587136Z","iopub.execute_input":"2022-05-30T21:37:38.587481Z","iopub.status.idle":"2022-05-30T21:37:39.934705Z","shell.execute_reply.started":"2022-05-30T21:37:38.587444Z","shell.execute_reply":"2022-05-30T21:37:39.933708Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%%cython\ndef LCS(str S, str T):\n    cdef int i, j\n    cdef list dp = [[0] * (len(T) + 1) for _ in range(len(S) + 1)]\n    for i in range(len(S)):\n        for j in range(len(T)):\n            dp[i + 1][j + 1] = max(dp[i][j] + (S[i] == T[j]), dp[i + 1][j], dp[i][j + 1], dp[i + 1][j + 1])\n    return dp[len(S)][len(T)]","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:37:39.935997Z","iopub.execute_input":"2022-05-30T21:37:39.936296Z","iopub.status.idle":"2022-05-30T21:37:41.386329Z","shell.execute_reply.started":"2022-05-30T21:37:39.936268Z","shell.execute_reply":"2022-05-30T21:37:41.385007Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def init_train_data(df,knn_data,true_matches):\n    ids = []\n    match_ids = []\n    label = []\n    \n    for k in tqdm(knn_data.keys()):\n        # true match\n        for m in true_matches.get(k):\n            ids.append(k)\n            match_ids.append(m)\n            label.append(1)\n        # false match\n        for m in knn_data.get(k):\n            if not(m in true_matches.get(k)):\n                ids.append(k)\n                match_ids.append(m)\n                label.append(0)\n    \n    df['id'] = ids\n    df['match_id'] = match_ids\n    '''\n    # add knn haversine distance\n    id_1 = [train.loc[df.id].latitude.values,train.loc[df.id].longitude.values]\n    id_2 = [train.loc[df.match_id].latitude.values,train.loc[df.match_id].longitude.values]\n    dist = []\n    for i in tqdm(range(len(id_1[0]))):\n        a = [id_1[0][i],id_1[1][i]]\n        b = [id_2[0][i],id_2[1][i]]\n        dist.append(haversine(a,b))\n\n    df['dist'] = dist\n    \n    del id_1[:]\n    del id_1\n    del id_2[:]\n    del id_2\n    del dist[:]\n    del dist\n    '''\n    del ids[:]\n    del ids\n    del match_ids[:]\n    del match_ids\n    \n    label_counter = collections.Counter(label)\n    print('true match:',label_counter[1]/(label_counter[1]+label_counter[0]))\n    print('false match:',label_counter[0]/(label_counter[1]+label_counter[0]))\n        \n    return df, label","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:37:41.388140Z","iopub.execute_input":"2022-05-30T21:37:41.388535Z","iopub.status.idle":"2022-05-30T21:37:41.400167Z","shell.execute_reply.started":"2022-05-30T21:37:41.388495Z","shell.execute_reply":"2022-05-30T21:37:41.399056Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"neighbors = 10\nknn_data,knn_dist = find_neighbors(train,neighbors)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T21:37:41.402269Z","iopub.execute_input":"2022-05-30T21:37:41.402656Z","iopub.status.idle":"2022-05-30T22:00:40.109346Z","shell.execute_reply.started":"2022-05-30T21:37:41.402624Z","shell.execute_reply":"2022-05-30T22:00:40.108200Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"del knn_dist","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:00:40.110914Z","iopub.execute_input":"2022-05-30T22:00:40.111363Z","iopub.status.idle":"2022-05-30T22:00:40.506366Z","shell.execute_reply.started":"2022-05-30T22:00:40.111319Z","shell.execute_reply":"2022-05-30T22:00:40.505399Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# generate training data\ntrain = pd.read_csv('../input/foursquare-location-matching/train.csv')\ndf = pd.DataFrame()\nfeatures_col = ['name','categories','address','state','city','country']\n\n# fill nan\nfor col in features_col:\n    train[col].fillna('nan',inplace=True)\ntrain.set_index('id',inplace=True)\n\ndf, label = init_train_data(df,knn_data,true_matches)\n# train_data = add_features(train_data,features_col)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:00:40.510812Z","iopub.execute_input":"2022-05-30T22:00:40.511309Z","iopub.status.idle":"2022-05-30T22:01:03.903795Z","shell.execute_reply.started":"2022-05-30T22:00:40.511259Z","shell.execute_reply":"2022-05-30T22:01:03.902563Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:01:03.905053Z","iopub.execute_input":"2022-05-30T22:01:03.905397Z","iopub.status.idle":"2022-05-30T22:01:03.923833Z","shell.execute_reply.started":"2022-05-30T22:01:03.905367Z","shell.execute_reply":"2022-05-30T22:01:03.922517Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# split data\nn = 5\ndf_split = np.array_split(df, n)\ndel df","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:01:03.927292Z","iopub.execute_input":"2022-05-30T22:01:03.927689Z","iopub.status.idle":"2022-05-30T22:01:07.218838Z","shell.execute_reply.started":"2022-05-30T22:01:03.927656Z","shell.execute_reply":"2022-05-30T22:01:07.217896Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# add features\nfor nn in range(n):\n    sub_df = df_split[nn]\n    for col in features_col:\n            print('column:',col)\n\n            geshs = []\n            levens = []\n            jaros = []\n            lcss = []\n\n            col_values = train.loc[sub_df['id']][col].values.astype(str)\n            matcol_values = train.loc[sub_df['match_id']][col].values.astype(str)\n\n            for i in tqdm(range(len(col_values))):\n                s = col_values[i]\n                match_s = matcol_values[i]\n                if s != 'nan' and match_s != 'nan':                    \n                    geshs.append(difflib.SequenceMatcher(None, s, match_s).ratio())\n                    levens.append(Levenshtein.distance(s, match_s))\n                    jaros.append(Levenshtein.jaro_winkler(s, match_s))\n                    lcss.append(LCS(str(s), str(match_s)))\n                else:\n                    geshs.append(np.nan)\n                    levens.append(np.nan)\n                    jaros.append(np.nan)\n                    lcss.append(np.nan)\n            sub_df[f'{col}_gesh'] = geshs\n            sub_df[f'{col}_leven'] = levens\n            sub_df[f'{col}_jaro'] = jaros\n            sub_df[f'{col}_lcs'] = lcss\n\n            # features about string length\n            if col in ['name','country','categories']:\n                sub_df[f'{col}_len'] = list(map(len, col_values))\n                sub_df[f'match_{col}_len'] = list(map(len, matcol_values)) \n                sub_df[f'{col}_len_diff'] = np.abs(sub_df[f'{col}_len'] - sub_df[f'match_{col}_len'])\n                sub_df[f'{col}_nleven'] = sub_df[f'{col}_leven'] / sub_df[[f'{col}_len', f'match_{col}_len']].max(axis = 1)\n\n                sub_df[f'{col}_nlcsk'] = sub_df[f'{col}_lcs'] / sub_df[f'match_{col}_len']\n                sub_df[f'{col}_nlcs'] = sub_df[f'{col}_lcs'] / sub_df[f'{col}_len']\n\n                sub_df = sub_df.drop(f'{col}_len', axis = 1)\n                sub_df = sub_df.drop(f'match_{col}_len', axis = 1)\n            \n    sub_df.to_csv('../working/train_data'+str(nn+1)+'.csv', index = False)\n    del sub_df","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:01:07.220475Z","iopub.execute_input":"2022-05-30T22:01:07.221133Z","iopub.status.idle":"2022-05-30T23:28:12.451487Z","shell.execute_reply.started":"2022-05-30T22:01:07.221084Z","shell.execute_reply":"2022-05-30T23:28:12.447934Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# clear memory usage of list\ndel col_values\ndel matcol_values\ndel geshs[:]\ndel geshs\ndel levens[:]\ndel levens\ndel jaros[:]\ndel jaros\ndel lcss[:]\ndel lcss\ndel knn_data\ndel train\ndel df_split","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:28:12.457904Z","iopub.execute_input":"2022-05-30T23:28:12.458574Z","iopub.status.idle":"2022-05-30T23:28:14.542766Z","shell.execute_reply.started":"2022-05-30T23:28:12.458504Z","shell.execute_reply":"2022-05-30T23:28:14.541773Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"# concate training data\ntrain_data = pd.DataFrame()\n\nfor i in tqdm(range(n)):\n    temp = pd.read_csv('../working/train_data'+str(i+1)+'.csv')\n    \n    # reduce memory usage\n    # int64 to unit8\n    df_int = temp.select_dtypes(include=['int'])\n    converted_int = df_int.apply(pd.to_numeric,downcast='unsigned')\n    for cc in df_int.columns:\n         temp[cc] = converted_int[cc]\n    # float64 to float32\n    df_float = temp.select_dtypes(include=['float'])\n    converted_float = df_float.apply(pd.to_numeric,downcast='float')\n    for cc in df_float.columns:\n        temp[cc] = converted_float[cc]\n        \n    train_data = pd.concat([train_data,temp])\n    del temp\n","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:28:14.544575Z","iopub.execute_input":"2022-05-30T23:28:14.544914Z","iopub.status.idle":"2022-05-30T23:30:02.893405Z","shell.execute_reply.started":"2022-05-30T23:28:14.544884Z","shell.execute_reply":"2022-05-30T23:30:02.892339Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del df_int\ndel converted_int\ndel df_float\ndel converted_float","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:30:02.894885Z","iopub.execute_input":"2022-05-30T23:30:02.895232Z","iopub.status.idle":"2022-05-30T23:30:02.903220Z","shell.execute_reply.started":"2022-05-30T23:30:02.895200Z","shell.execute_reply":"2022-05-30T23:30:02.902521Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_data.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:30:02.904522Z","iopub.execute_input":"2022-05-30T23:30:02.905540Z","iopub.status.idle":"2022-05-30T23:30:07.692813Z","shell.execute_reply.started":"2022-05-30T23:30:02.905496Z","shell.execute_reply":"2022-05-30T23:30:07.692032Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:30:07.694007Z","iopub.execute_input":"2022-05-30T23:30:07.694467Z","iopub.status.idle":"2022-05-30T23:30:07.732699Z","shell.execute_reply.started":"2022-05-30T23:30:07.694434Z","shell.execute_reply":"2022-05-30T23:30:07.731864Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# generate train and test data\nX = train_data.drop(columns=['id','match_id'])\ny = label\ndel train_data\ndel label","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:30:07.733970Z","iopub.execute_input":"2022-05-30T23:30:07.734309Z","iopub.status.idle":"2022-05-30T23:30:09.789297Z","shell.execute_reply.started":"2022-05-30T23:30:07.734278Z","shell.execute_reply":"2022-05-30T23:30:09.788217Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\nprint('X_train:', X_train.shape)\nprint('X_test:', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:30:09.790952Z","iopub.execute_input":"2022-05-30T23:30:09.791303Z","iopub.status.idle":"2022-05-30T23:30:28.435973Z","shell.execute_reply.started":"2022-05-30T23:30:09.791270Z","shell.execute_reply":"2022-05-30T23:30:28.434849Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# LightGBM\nmodel = lgb.LGBMClassifier(is_unbalance=True,learning_rate=0.05)\nmodel.fit(X_train,y_train)\nmodel.booster_.save_model('../working/lgb_model.txt')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:30:28.437768Z","iopub.execute_input":"2022-05-30T23:30:28.438691Z","iopub.status.idle":"2022-05-30T23:32:01.402613Z","shell.execute_reply.started":"2022-05-30T23:30:28.438642Z","shell.execute_reply":"2022-05-30T23:32:01.401575Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# load model and predict\nmodel_load = lgb.Booster(model_file='../working/lgb_model.txt')\npred = model_load.predict(X_test) # return probability","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:32:01.404732Z","iopub.execute_input":"2022-05-30T23:32:01.405277Z","iopub.status.idle":"2022-05-30T23:32:11.675953Z","shell.execute_reply.started":"2022-05-30T23:32:01.405232Z","shell.execute_reply":"2022-05-30T23:32:11.675074Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"del X_train\ndel y_train","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:32:11.679928Z","iopub.execute_input":"2022-05-30T23:32:11.680838Z","iopub.status.idle":"2022-05-30T23:32:11.711194Z","shell.execute_reply.started":"2022-05-30T23:32:11.680787Z","shell.execute_reply":"2022-05-30T23:32:11.710084Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# caculate accuracy\nTP = 0\nTN = 0\nFP = 0\nFN = 0\nthreshold = 0.5\nfor i in range(len(pred)):\n    if pred[i] >= threshold:\n        if y_test[i] == 1:\n            TP += 1\n        else:\n            FP += 1\n    else:\n        if y_test[i] == 0:\n            TN += 1\n        else:\n            FN += 1\n    \nprecision = TP / (TP+FP)\nrecall = TP / (TP+FN)\nf1_score = (2*precision*recall) / (precision+recall)\n\nprint('F1 score',f1_score)\nprint('Accuracy',(TP+TN)/(TP+TN+FP+FN))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T23:32:11.713283Z","iopub.execute_input":"2022-05-30T23:32:11.714120Z","iopub.status.idle":"2022-05-30T23:32:14.278589Z","shell.execute_reply.started":"2022-05-30T23:32:11.714070Z","shell.execute_reply":"2022-05-30T23:32:14.277528Z"},"trusted":true},"execution_count":24,"outputs":[]}]}